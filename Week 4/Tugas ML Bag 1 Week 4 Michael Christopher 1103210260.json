{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ames Housing Dataset: Exploratory Data Analysis, Feature Engineering, dan Prediksi Harga Rumah\n",
        "\n",
        "Notebook ini bertujuan untuk melakukan analisis menyeluruh pada dataset Ames Housing untuk memprediksi harga rumah. Kita akan melakukan:\n",
        "\n",
        "1. **Exploratory Data Analysis (EDA)** - Memahami dataset dan pola-pola yang ada\n",
        "2. **Feature Engineering** - Menciptakan dan memilih fitur yang relevan\n",
        "3. **Data Visualization** - Visualisasi untuk pemahaman yang lebih baik\n",
        "4. **Model Building** - Membangun model prediksi harga rumah\n",
        "5. **Model Evaluation** - Evaluasi model menggunakan metrik yang sesuai\n",
        "\n",
        "Dataset ini berisi informasi tentang penjualan rumah di Ames, Iowa antara tahun 2006 dan 2010."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import Library dan Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Import library yang dibutuhkan\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "import warnings\n",
        "\n",
        "# Mengabaikan warning untuk tampilan yang lebih bersih\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Konfigurasi tampilan\n",
        "pd.set_option('display.max_columns', None)\n",
        "plt.style.use('ggplot')\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Seed untuk reproducibility\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Membaca dataset\n",
        "train_data = pd.read_csv('train.csv')\n",
        "test_data = pd.read_csv('test.csv')\n",
        "\n",
        "# Simpan ID test untuk submit nanti\n",
        "test_ID = test_data['Id']\n",
        "\n",
        "# Tampilkan ukuran dataset\n",
        "print(f\"Training data shape: {train_data.shape}\")\n",
        "print(f\"Testing data shape: {test_data.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Exploratory Data Analysis (EDA)\n",
        "\n",
        "Pada bagian ini, kita akan mengeksplorasi dataset untuk mendapatkan pemahaman yang lebih baik tentang data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Menampilkan ringkasan statistik untuk variabel numerik pada data training\n",
        "train_data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Cek informasi data\n",
        "train_data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Analisis Variabel Target (SalePrice)\n",
        "\n",
        "Kita akan menganalisis variabel target 'SalePrice' untuk memahami distribusinya."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Statistik deskriptif SalePrice\n",
        "print(train_data['SalePrice'].describe())\n",
        "\n",
        "# Visualisasi distribusi harga\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.histplot(train_data['SalePrice'], kde=True, color='blue')\n",
        "plt.title('Distribusi SalePrice', fontsize=14)\n",
        "plt.xlabel('Harga (USD)', fontsize=12)\n",
        "plt.ylabel('Frekuensi', fontsize=12)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "stats.probplot(train_data['SalePrice'], plot=plt)\n",
        "plt.title('Q-Q Plot SalePrice', fontsize=14)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Skewness dan Kurtosis\n",
        "print(f\"Skewness: {train_data['SalePrice'].skew()}\")\n",
        "print(f\"Kurtosis: {train_data['SalePrice'].kurt()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dari analisis di atas, kita dapat melihat bahwa distribusi SalePrice memiliki skewness positif (right-skewed). Ini menunjukkan ada beberapa rumah dengan harga sangat tinggi (outliers). Kita perlu melakukan transformasi logaritmik pada SalePrice untuk menormalkan distribusinya."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Transformasi logaritmik pada SalePrice\n",
        "train_data['SalePrice_Log'] = np.log1p(train_data['SalePrice'])\n",
        "\n",
        "# Visualisasi hasil transformasi\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.histplot(train_data['SalePrice_Log'], kde=True, color='green')\n",
        "plt.title('Distribusi Log(SalePrice)', fontsize=14)\n",
        "plt.xlabel('Log(Harga)', fontsize=12)\n",
        "plt.ylabel('Frekuensi', fontsize=12)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "stats.probplot(train_data['SalePrice_Log'], plot=plt)\n",
        "plt.title('Q-Q Plot Log(SalePrice)', fontsize=14)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Skewness dan Kurtosis setelah transformasi\n",
        "print(f\"Skewness: {train_data['SalePrice_Log'].skew()}\")\n",
        "print(f\"Kurtosis: {train_data['SalePrice_Log'].kurt()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Distribusi menjadi lebih normal setelah transformasi logaritmik, yang akan membantu model regresi kita."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Analisis Missing Values\n",
        "\n",
        "Kita akan memeriksa dan menangani nilai-nilai yang hilang dalam dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Fungsi untuk menampilkan persentase missing values\n",
        "def missing_values_analysis(df):\n",
        "    # Menghitung persentase missing values\n",
        "    missing = pd.DataFrame(df.isnull().sum(), columns=['Missing Values'])\n",
        "    missing['Percentage'] = (missing['Missing Values'] / len(df)) * 100\n",
        "    \n",
        "    # Filter kolom dengan missing values\n",
        "    missing = missing[missing['Missing Values'] > 0].sort_values('Percentage', ascending=False)\n",
        "    \n",
        "    return missing\n",
        "\n",
        "# Analisis missing values pada data train\n",
        "missing_train = missing_values_analysis(train_data)\n",
        "print(\"Missing values dalam data training:\")\n",
        "print(missing_train)\n",
        "\n",
        "# Analisis missing values pada data test\n",
        "missing_test = missing_values_analysis(test_data)\n",
        "print(\"\\nMissing values dalam data testing:\")\n",
        "print(missing_test)\n",
        "\n",
        "# Visualisasi missing values\n",
        "plt.figure(figsize=(14, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.heatmap(train_data.isnull(), cbar=False, cmap='viridis')\n",
        "plt.title('Missing Values - Training Data', fontsize=14)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.heatmap(test_data.isnull(), cbar=False, cmap='viridis')\n",
        "plt.title('Missing Values - Testing Data', fontsize=14)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Kita dapat melihat beberapa pola dalam missing values:\n",
        "\n",
        "1. Beberapa kolom seperti 'PoolQC', 'MiscFeature', 'Alley', 'Fence' memiliki persentase missing values yang sangat tinggi.\n",
        "2. Kolom-kolom yang terkait dengan basement (BsmtQual, BsmtCond, dll.) dan garasi (GarageType, GarageFinish, dll.) juga memiliki missing values.\n",
        "\n",
        "Beberapa missing values ini sebenarnya bukan \"missing\" dalam arti tidak ada data, tapi menandakan bahwa fitur tersebut tidak ada dalam rumah tersebut. Misalnya, \"NA\" dalam PoolQC berarti rumah tidak memiliki kolam renang."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Kita akan menggabungkan data train dan test untuk data preprocessing\n",
        "# Simpan target variable terlebih dahulu\n",
        "train_labels = train_data['SalePrice']\n",
        "\n",
        "# Gabungkan data untuk preprocessing\n",
        "all_data = pd.concat([train_data.drop(['SalePrice', 'SalePrice_Log'], axis=1), test_data], axis=0)\n",
        "print(f\"Combined data shape: {all_data.shape}\")\n",
        "\n",
        "# Identifikasi kolom numerik dan kategorikal\n",
        "numerical_cols = all_data.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_cols = all_data.select_dtypes(include=['object']).columns\n",
        "\n",
        "print(f\"Jumlah kolom numerik: {len(numerical_cols)}\")\n",
        "print(f\"Jumlah kolom kategorikal: {len(categorical_cols)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3 Analisis Fitur Numerik\n",
        "\n",
        "Kita akan menganalisis dan memvisualisasikan fitur-fitur numerik penting dan hubungannya dengan SalePrice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Pilih kolom numerik yang penting\n",
        "important_num_cols = ['OverallQual', 'GrLivArea', 'TotalBsmtSF', '1stFlrSF', 'GarageArea', 'FullBath', 'YearBuilt', 'YearRemodAdd']\n",
        "\n",
        "# Korelasi dengan SalePrice\n",
        "correlation = train_data[important_num_cols + ['SalePrice']].corr()\n",
        "print(correlation['SalePrice'].sort_values(ascending=False))\n",
        "\n",
        "# Heatmap korelasi\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(correlation, annot=True, cmap='coolwarm', linewidths=0.5)\n",
        "plt.title('Korelasi antar Fitur Numerik', fontsize=16)\n",
        "plt.show()\n",
        "\n",
        "# Scatter plot untuk fitur numerik terhadap SalePrice\n",
        "fig, axes = plt.subplots(4, 2, figsize=(16, 20))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, col in enumerate(important_num_cols):\n",
        "    sns.regplot(x=col, y='SalePrice', data=train_data, ax=axes[i], scatter_kws={'alpha':0.5}, line_kws={'color':'red'})\n",
        "    axes[i].set_title(f'SalePrice vs {col}', fontsize=14)\n",
        "    axes[i].ticklabel_format(style='plain', axis='y')\n",
        "    \n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Berdasarkan analisis korelasi:\n",
        "\n",
        "1. **OverallQual** (kualitas keseluruhan rumah) memiliki korelasi tertinggi dengan SalePrice, menunjukkan kualitas adalah prediktor penting.\n",
        "2. **GrLivArea** (luas area hidup) juga memiliki korelasi kuat, yang masuk akal karena rumah yang lebih besar cenderung lebih mahal.\n",
        "3. **YearBuilt** (tahun pembangunan) dan **YearRemodAdd** (tahun renovasi) menunjukkan rumah yang lebih baru cenderung lebih mahal.\n",
        "4. Ada beberapa outlier yang terlihat di scatter plot, terutama untuk GrLivArea."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Mendeteksi outliers di GrLivArea\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x='GrLivArea', y='SalePrice', data=train_data)\n",
        "plt.title('Outliers di GrLivArea', fontsize=14)\n",
        "plt.xlabel('GrLivArea (square feet)', fontsize=12)\n",
        "plt.ylabel('SalePrice ($)', fontsize=12)\n",
        "plt.show()\n",
        "\n",
        "# Mengidentifikasi outliers di GrLivArea dengan area >4000 dan harga rendah\n",
        "outliers = train_data[(train_data['GrLivArea'] > 4000) & (train_data['SalePrice'] < 300000)].index\n",
        "print(f\"Outlier indices: {outliers}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Kita menemukan beberapa outlier di GrLivArea yang memiliki area besar tapi harga relatif rendah. Outlier ini dapat mempengaruhi model kita, jadi kita akan menghapusnya."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Hapus outliers dari data training\n",
        "train_data_clean = train_data.drop(outliers)\n",
        "print(f\"Data training setelah menghapus outliers: {train_data_clean.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.4 Analisis Fitur Kategorikal\n",
        "\n",
        "Kita akan menganalisis dan memvisualisasikan fitur-fitur kategorikal penting dan pengaruhnya terhadap SalePrice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Pilih fitur kategorikal yang penting\n",
        "important_cat_cols = ['Neighborhood', 'ExterQual', 'BsmtQual', 'KitchenQual', 'GarageType', 'SaleCondition', 'MSZoning', 'HouseStyle']\n",
        "\n",
        "# Boxplot untuk kategorikal vs SalePrice\n",
        "fig, axes = plt.subplots(4, 2, figsize=(18, 24))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, col in enumerate(important_cat_cols):\n",
        "    # Sort boxplot by median SalePrice\n",
        "    median_price = train_data_clean.groupby(col)['SalePrice'].median().sort_values(ascending=False).index\n",
        "    sns.boxplot(x=col, y='SalePrice', data=train_data_clean, order=median_price, ax=axes[i], palette='Set3')\n",
        "    axes[i].set_title(f'SalePrice by {col}', fontsize=14)\n",
        "    axes[i].ticklabel_format(style='plain', axis='y')\n",
        "    axes[i].set_xticklabels(axes[i].get_xticklabels(), rotation=45, ha='right')\n",
        "    \n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Analisis fitur kategorikal menunjukkan:\n",
        "\n",
        "1. **Neighborhood** memiliki pengaruh signifikan terhadap harga rumah, dengan beberapa lingkungan memiliki median harga jauh lebih tinggi dari yang lain.\n",
        "2. **ExterQual**, **BsmtQual**, dan **KitchenQual** (kualitas eksterior, basement, dan dapur) menunjukkan pattern yang jelas - kualitas lebih tinggi berarti harga lebih tinggi.\n",
        "3. **GarageType** dan **SaleCondition** juga mempengaruhi harga, meskipun dengan variasi yang lebih besar.\n",
        "\n",
        "Insight ini akan membantu kita dalam feature engineering untuk meningkatkan performa model prediksi."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Distribusi frekuensi untuk fitur kategorikal\n",
        "fig, axes = plt.subplots(4, 2, figsize=(18, 20))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, col in enumerate(important_cat_cols):\n",
        "    value_counts = train_data_clean[col].value_counts().sort_values(ascending=False)\n",
        "    sns.barplot(x=value_counts.index, y=value_counts.values, ax=axes[i], palette='viridis')\n",
        "    axes[i].set_title(f'Frekuensi {col}', fontsize=14)\n",
        "    axes[i].set_xticklabels(axes[i].get_xticklabels(), rotation=45, ha='right')\n",
        "    \n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Distribusi frekuensi menunjukkan bahwa beberapa kategori memiliki jumlah sampel yang sangat sedikit. Ini bisa menjadi masalah saat encoding fitur kategorikal, jadi kita perlu mempertimbangkan strategi encoding yang tepat."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Feature Engineering\n",
        "\n",
        "Berdasarkan EDA, kita akan melakukan feature engineering untuk meningkatkan performa model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Gunakan data train yang sudah dibersihkan dari outliers\n",
        "train_labels_clean = train_data_clean['SalePrice']\n",
        "train_features_clean = train_data_clean.drop(['SalePrice', 'SalePrice_Log', 'Id'], axis=1)\n",
        "test_features = test_data.drop(['Id'], axis=1)\n",
        "\n",
        "# Gabungkan untuk preprocessing feature\n",
        "all_features = pd.concat([train_features_clean, test_features]).reset_index(drop=True)\n",
        "print(f\"Combined features shape: {all_features.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 Penanganan Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Identifikasi kolom dengan missing values dan tipe data yang sesuai\n",
        "na_cols = missing_values_analysis(all_features)\n",
        "print(f\"Total kolom dengan missing values: {len(na_cols)}\")\n",
        "\n",
        "# Kategorikan kolom missing value berdasarkan artinya\n",
        "# 1. Missing karena fitur tidak ada (NA berarti None)\n",
        "na_as_none = ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'MasVnrType']\n",
        "\n",
        "# 2. Missing numerik yang perlu diisi dengan nilai yang sesuai\n",
        "na_numeric = ['LotFrontage', 'GarageYrBlt', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath', 'GarageArea', 'GarageCars']\n",
        "\n",
        "# 3. Missing kategorikal yang perlu diisi dengan mode\n",
        "na_categorical = [col for col in all_features.columns if col not in na_as_none + na_numeric and col in na_cols.index]\n",
        "\n",
        "print(\"\\nFitur dengan NA yang berarti tidak ada fitur tersebut:\")\n",
        "print(na_as_none)\n",
        "print(\"\\nFitur numerik dengan missing values:\")\n",
        "print(na_numeric)\n",
        "print(\"\\nFitur kategorikal dengan missing values:\")\n",
        "print(na_categorical)\n",
        "\n",
        "# Penanganan missing values\n",
        "# 1. NA sebagai 'None' untuk fitur kategorikal\n",
        "for col in na_as_none:\n",
        "    if col in all_features.columns:\n",
        "        all_features[col] = all_features[col].fillna('None')\n",
        "\n",
        "# 2. Imputasi untuk fitur numerik\n",
        "for col in na_numeric:\n",
        "    if col in all_features.columns:\n",
        "        # Untuk LotFrontage, imputasi berdasarkan Neighborhood\n",
        "        if col == 'LotFrontage':\n",
        "            all_features[col] = all_features.groupby('Neighborhood')['LotFrontage'].transform(\n",
        "                lambda x: x.fillna(x.median()))\n",
        "        # Untuk GarageYrBlt, gunakan YearBuilt jika tidak ada\n",
        "        elif col == 'GarageYrBlt':\n",
        "            all_features[col] = all_features[col].fillna(all_features['YearBuilt'])\n",
        "        # Untuk lainnya, imputasi dengan 0 karena tidak adanya fitur sesuai dengan nilai 0\n",
        "        else:\n",
        "            all_features[col] = all_features[col].fillna(0)\n",
        "\n",
        "# 3. Imputasi untuk fitur kategorikal dengan mode\n",
        "for col in na_categorical:\n",
        "    if col in all_features.columns:\n",
        "        all_features[col] = all_features[col].fillna(all_features[col].mode()[0])\n",
        "\n",
        "# Cek apakah masih ada missing values\n",
        "na_after = missing_values_analysis(all_features)\n",
        "if len(na_after) > 0:\n",
        "    print(\"\\nMissing values yang tersisa:\")\n",
        "    print(na_after)\n",
        "else:\n",
        "    print(\"\\nSemua missing values telah ditangani.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Transformasi dan Pembuatan Fitur Baru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# 1. Total luas area\n",
        "all_features['TotalSF'] = all_features['TotalBsmtSF'] + all_features['1stFlrSF'] + all_features['2ndFlrSF']\n",
        "\n",
        "# 2. Total kamar mandi\n",
        "all_features['TotalBathrooms'] = all_features['FullBath'] + (0.5 * all_features['HalfBath']) + \\\n",
        "                                all_features['BsmtFullBath'] + (0.5 * all_features['BsmtHalfBath'])\n",
        "\n",
        "# 3. Umur rumah saat dijual\n",
        "all_features['HouseAge'] = all_features['YrSold'] - all_features['YearBuilt']\n",
        "\n",
        "# 4. Lama sejak renovasi terakhir\n",
        "all_features['RemodAge'] = all_features['YrSold'] - all_features['YearRemodAdd']\n",
        "\n",
        "# 5. Apakah rumah direnovasi\n",
        "all_features['IsRemodeled'] = (all_features['YearRemodAdd'] != all_features['YearBuilt']).astype(int)\n",
        "\n",
        "# 6. Apakah rumah baru\n",
        "all_features['IsNewHouse'] = (all_features['HouseAge'] <= 2).astype(int)\n",
        "\n",
        "# 7. Porch area total\n",
        "all_features['TotalPorchSF'] = all_features['OpenPorchSF'] + all_features['EnclosedPorch'] + \\\n",
        "                             all_features['3SsnPorch'] + all_features['ScreenPorch']\n",
        "\n",
        "# 8. Rasio luas lantai 2 terhadap lantai 1\n",
        "all_features['FlrRatio'] = all_features['2ndFlrSF'] / (all_features['1stFlrSF'] + 1)  # +1 untuk menghindari pembagian dengan nol\n",
        "\n",
        "# 9. Kategori kualitas keseluruhan\n",
        "all_features['QualityCat'] = pd.cut(all_features['OverallQual'], \n",
        "                                    bins=[0, 3, 5, 7, 10], \n",
        "                                    labels=['Low', 'Average', 'Good', 'Excellent'])\n",
        "\n",
        "# 10. Apakah memiliki kolam renang\n",
        "all_features['HasPool'] = (all_features['PoolArea'] > 0).astype(int)\n",
        "\n",
        "# 11. Apakah memiliki garasi\n",
        "all_features['HasGarage'] = (all_features['GarageArea'] > 0).astype(int)\n",
        "\n",
        "# 12. Apakah memiliki basement\n",
        "all_features['HasBasement'] = (all_features['TotalBsmtSF'] > 0).astype(int)\n",
        "\n",
        "# 13. Apakah memiliki perapian\n",
        "all_features['HasFireplace'] = (all_features['Fireplaces'] > 0).astype(int)\n",
        "\n",
        "# 14. Gabungan berbagai kualitas\n",
        "def map_quality(x):\n",
        "    quality_map = {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5}\n",
        "    return quality_map.get(x, 0)\n",
        "\n",
        "all_features['OverallGrade'] = all_features['ExterQual'].map(map_quality) + \\\n",
        "                             all_features['KitchenQual'].map(map_quality) + \\\n",
        "                             all_features['BsmtQual'].map(map_quality) + \\\n",
        "                             all_features['FireplaceQu'].map(map_quality) + \\\n",
        "                             all_features['GarageQual'].map(map_quality)\n",
        "\n",
        "# Lihat fitur baru\n",
        "print(\"Fitur baru yang dibuat:\")\n",
        "new_features = ['TotalSF', 'TotalBathrooms', 'HouseAge', 'RemodAge', 'IsRemodeled', 'IsNewHouse', \n",
        "                'TotalPorchSF', 'FlrRatio', 'QualityCat', 'HasPool', 'HasGarage', 'HasBasement', \n",
        "                'HasFireplace', 'OverallGrade']\n",
        "print(all_features[new_features].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 Transformasi Skew untuk Fitur Numerik\n",
        "\n",
        "Beberapa fitur numerik memiliki skew tinggi yang dapat mempengaruhi model. Kita akan melakukan transformasi logaritmik pada fitur-fitur tersebut."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Identifikasi fitur numerik dengan skew tinggi\n",
        "numeric_feats = all_features.dtypes[all_features.dtypes != 'object'].index\n",
        "skew_feats = all_features[numeric_feats].apply(lambda x: stats.skew(x.dropna())).sort_values(ascending=False)\n",
        "high_skew = skew_feats[skew_feats > 0.75]\n",
        "print(f\"Jumlah fitur numerik dengan skew tinggi: {len(high_skew)}\")\n",
        "print(\"Fitur dengan skew tertinggi:\")\n",
        "print(high_skew.head(10))\n",
        "\n",
        "# Transformasi log1p pada fitur dengan skew tinggi\n",
        "for feat in high_skew.index:\n",
        "    if feat in all_features.columns and feat not in ['IsRemodeled', 'IsNewHouse', 'HasPool', 'HasGarage', 'HasBasement', 'HasFireplace']:\n",
        "        all_features[feat] = np.log1p(all_features[feat])\n",
        "\n",
        "# Cek skew setelah transformasi\n",
        "after_transform_skew = all_features[high_skew.index].apply(lambda x: stats.skew(x.dropna())).sort_values(ascending=False)\n",
        "print(\"\\nSkew setelah transformasi:\")\n",
        "print(after_transform_skew.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.4 Encoding Fitur Kategorikal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Identifikasi fitur kategorikal setelah transformasi\n",
        "categorical_feats = all_features.dtypes[all_features.dtypes == 'object'].index.tolist() + ['QualityCat']\n",
        "print(f\"Jumlah fitur kategorikal: {len(categorical_feats)}\")\n",
        "\n",
        "# Cek jumlah kategori\n",
        "print(\"Jumlah kategori untuk setiap fitur kategorikal:\")\n",
        "for col in categorical_feats:\n",
        "    print(f\"{col}: {len(all_features[col].unique())} kategori\")\n",
        "\n",
        "# Encoding kategorikal dengan Label Encoding untuk kolom ordinal\n",
        "ordinal_features = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
        "                   'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond', 'PoolQC', 'Fence', 'QualityCat']\n",
        "\n",
        "# Mapping untuk fitur ordinal\n",
        "quality_map = {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5}\n",
        "exposure_map = {'None': 0, 'No': 1, 'Mn': 2, 'Av': 3, 'Gd': 4}\n",
        "fin_type_map = {'None': 0, 'Unf': 1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ': 5, 'GLQ': 6}\n",
        "fence_map = {'None': 0, 'MnWw': 1, 'GdWo': 2, 'MnPrv': 3, 'GdPrv': 4}\n",
        "quality_cat_map = {'Low': 0, 'Average': 1, 'Good': 2, 'Excellent': 3}\n",
        "\n",
        "# Encoding fitur ordinal\n",
        "for feat in ordinal_features:\n",
        "    if feat in all_features.columns:\n",
        "        if feat in ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond', 'PoolQC']:\n",
        "            all_features[feat] = all_features[feat].map(quality_map)\n",
        "        elif feat == 'BsmtExposure':\n",
        "            all_features[feat] = all_features[feat].map(exposure_map)\n",
        "        elif feat in ['BsmtFinType1', 'BsmtFinType2']:\n",
        "            all_features[feat] = all_features[feat].map(fin_type_map)\n",
        "        elif feat == 'Fence':\n",
        "            all_features[feat] = all_features[feat].map(fence_map)\n",
        "        elif feat == 'QualityCat':\n",
        "            all_features[feat] = all_features[feat].map(quality_cat_map)\n",
        "\n",
        "# One-hot encoding untuk fitur nominal\n",
        "nominal_features = [x for x in categorical_feats if x not in ordinal_features]\n",
        "all_features = pd.get_dummies(all_features, columns=nominal_features, drop_first=True)\n",
        "\n",
        "print(f\"\\nJumlah fitur setelah encoding: {all_features.shape[1]}\")\n",
        "print(all_features.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.5 Standardisasi Fitur Numerik"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Standardisasi fitur numerik\n",
        "numeric_features = [feat for feat in all_features.columns if feat not in categorical_feats and \n",
        "                   feat not in ['Id', 'IsRemodeled', 'IsNewHouse', 'HasPool', 'HasGarage', 'HasBasement', 'HasFireplace']]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "all_features[numeric_features] = scaler.fit_transform(all_features[numeric_features])\n",
        "\n",
        "print(f\"Fitur setelah standardisasi:\\n{all_features[numeric_features].head()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.6 Pemisahan Data Training dan Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Pisahkan data training dan testing\n",
        "n_train = len(train_data_clean)\n",
        "train_features_processed = all_features[:n_train].reset_index(drop=True)\n",
        "test_features_processed = all_features[n_train:].reset_index(drop=True)\n",
        "\n",
        "print(f\"Training features shape: {train_features_processed.shape}\")\n",
        "print(f\"Testing features shape: {test_features_processed.shape}\")\n",
        "\n",
        "# Log transform pada target variable untuk model\n",
        "train_labels_log = np.log1p(train_labels_clean)\n",
        "print(f\"Training labels shape: {train_labels_log.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Model Building dan Evaluasi\n",
        "\n",
        "Sekarang kita akan membangun dan mengevaluasi beberapa model regresi untuk memprediksi harga rumah."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1 Definisi Metrik Evaluasi\n",
        "\n",
        "#### 1. Mean Squared Error (MSE)\n",
        "$$\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$$\n",
        "\n",
        "Dimana:\n",
        "- $n$ adalah jumlah sampel\n",
        "- $y_i$ adalah nilai aktual\n",
        "- $\\hat{y}_i$ adalah nilai prediksi\n",
        "\n",
        "MSE mengukur rata-rata kuadrat dari error (selisih antara nilai prediksi dan aktual). Semakin kecil MSE semakin bagus model. MSE memberikan bobot lebih besar pada error yang besar karena error dikuadratkan.\n",
        "\n",
        "#### 2. Root Mean Squared Error (RMSE)\n",
        "$$\\text{RMSE} = \\sqrt{\\text{MSE}} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}$$\n",
        "\n",
        "RMSE adalah akar kuadrat dari MSE. RMSE lebih mudah diinterpretasi karena memiliki satuan yang sama dengan variabel target. Seperti MSE, semakin kecil RMSE semakin bagus model.\n",
        "\n",
        "#### 3. R-squared (R²)\n",
        "$$R^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}$$\n",
        "\n",
        "Dimana:\n",
        "- $\\bar{y}$ adalah rata-rata nilai aktual\n",
        "\n",
        "R² mengukur proporsi variasi dalam variabel dependen yang dapat dijelaskan oleh variabel independen. Nilai R² berkisar antara 0 dan 1. Nilai yang lebih tinggi menunjukkan model yang lebih baik. R² = 1 berarti model menjelaskan semua variabilitas dalam data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Fungsi untuk evaluasi model\n",
        "def evaluate_model(y_true, y_pred, model_name):\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    \n",
        "    print(f\"{model_name} Performance:\")\n",
        "    print(f\"MSE: {mse:.6f}\")\n",
        "    print(f\"RMSE: {rmse:.6f}\")\n",
        "    print(f\"R²: {r2:.6f}\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    return {\"mse\": mse, \"rmse\": rmse, \"r2\": r2}\n",
        "\n",
        "# Split data untuk evaluasi model\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    train_features_processed, train_labels_log, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Baseline Models\n",
        "\n",
        "Kita akan membuat beberapa model dasar untuk perbandingan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Model 1: Linear Regression\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "lr_pred = lr.predict(X_val)\n",
        "lr_metrics = evaluate_model(y_val, lr_pred, \"Linear Regression\")\n",
        "\n",
        "# Model 2: Ridge Regression\n",
        "ridge = Ridge(alpha=10.0)\n",
        "ridge.fit(X_train, y_train)\n",
        "ridge_pred = ridge.predict(X_val)\n",
        "ridge_metrics = evaluate_model(y_val, ridge_pred, \"Ridge Regression\")\n",
        "\n",
        "# Model 3: Lasso Regression\n",
        "lasso = Lasso(alpha=0.001)\n",
        "lasso.fit(X_train, y_train)\n",
        "lasso_pred = lasso.predict(X_val)\n",
        "lasso_metrics = evaluate_model(y_val, lasso_pred, \"Lasso Regression\")\n",
        "\n",
        "# Model 4: ElasticNet\n",
        "elastic = ElasticNet(alpha=0.001, l1_ratio=0.5)\n",
        "elastic.fit(X_train, y_train)\n",
        "elastic_pred = elastic.predict(X_val)\n",
        "elastic_metrics = evaluate_model(y_val, elastic_pred, \"ElasticNet\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3 Advanced Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Model 5: Random Forest\n",
        "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "rf_pred = rf.predict(X_val)\n",
        "rf_metrics = evaluate_model(y_val, rf_pred, \"Random Forest\")\n",
        "\n",
        "# Model 6: Gradient Boosting\n",
        "gb = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "gb.fit(X_train, y_train)\n",
        "gb_pred = gb.predict(X_val)\n",
        "gb_metrics = evaluate_model(y_val, gb_pred, \"Gradient Boosting\")\n",
        "\n",
        "# Model 7: XGBoost\n",
        "xgb_reg = xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "xgb_reg.fit(X_train, y_train)\n",
        "xgb_pred = xgb_reg.predict(X_val)\n",
        "xgb_metrics = evaluate_model(y_val, xgb_pred, \"XGBoost\")\n",
        "\n",
        "# Model 8: LightGBM\n",
        "lgb_reg = lgb.LGBMRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "lgb_reg.fit(X_train, y_train)\n",
        "lgb_pred = lgb_reg.predict(X_val)\n",
        "lgb_metrics = evaluate_model(y_val, lgb_pred, \"LightGBM\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.4 Perbandingan Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Perbandingan semua model\n",
        "models = {\n",
        "    \"Linear Regression\": lr_metrics,\n",
        "    \"Ridge Regression\": ridge_metrics,\n",
        "    \"Lasso Regression\": lasso_metrics,\n",
        "    \"ElasticNet\": elastic_metrics,\n",
        "    \"Random Forest\": rf_metrics,\n",
        "    \"Gradient Boosting\": gb_metrics,\n",
        "    \"XGBoost\": xgb_metrics,\n",
        "    \"LightGBM\": lgb_metrics\n",
        "}\n",
        "\n",
        "comparison = pd.DataFrame({\n",
        "    'Model': list(models.keys()),\n",
        "    'MSE': [models[m]['mse'] for m in models],\n",
        "    'RMSE': [models[m]['rmse'] for m in models],\n",
        "    'R²': [models[m]['r2'] for m in models]\n",
        "})\n",
        "\n",
        "# Urutkan berdasarkan RMSE (semakin kecil semakin baik)\n",
        "comparison = comparison.sort_values('RMSE')\n",
        "comparison.reset_index(drop=True, inplace=True)\n",
        "print(\"Peringkat Model berdasarkan RMSE:\")\n",
        "print(comparison)\n",
        "\n",
        "# Visualisasi perbandingan model\n",
        "plt.figure(figsize=(14, 8))\n",
        "\n",
        "# RMSE\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.barplot(x='RMSE', y='Model', data=comparison, palette='viridis')\n",
        "plt.title('RMSE by Model (Lower is Better)', fontsize=14)\n",
        "plt.grid(axis='x')\n",
        "\n",
        "# R²\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.barplot(x='R²', y='Model', data=comparison, palette='viridis')\n",
        "plt.title('R² by Model (Higher is Better)', fontsize=14)\n",
        "plt.grid(axis='x')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.5 Analisis Model Terbaik"
      ]
    },
	
  
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Pilih model terbaik (sesuaikan berdasarkan hasil di atas)\n",
        "best_model_name = comparison.iloc[0]['Model']\n",
        "print(f\"Model terbaik: {best_model_name}\")\n",
        "\n",
        "# Definisikan model terbaik\n",
        "if best_model_name == \"Linear Regression\":\n",
        "    best_model = lr\n",
        "elif best_model_name == \"Ridge Regression\":\n",
        "    best_model = ridge\n",
        "elif best_model_name == \"Lasso Regression\":\n",
        "    best_model = lasso\n",
        "elif best_model_name == \"ElasticNet\":\n",
        "    best_model = elastic\n",
        "elif best_model_name == \"Random Forest\":\n",
        "    best_model = rf\n",
        "elif best_model_name == \"Gradient Boosting\":\n",
        "    best_model = gb\n",
        "elif best_model_name == \"XGBoost\":\n",
        "    best_model = xgb_reg\n",
        "else:  # LightGBM\n",
        "    best_model = lgb_reg\n",
        "\n",
        "# Latih model terbaik dengan seluruh data training\n",
        "best_model.fit(train_features_processed, train_labels_log)\n",
        "\n",
	]
	},
		{
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
		"# Get feature importances\n",
		"if hasattr(best_model, 'feature_importances_'):\n",
		"    importances = best_model.feature_importances_\n",
		"else:\n",
		"    importances = np.abs(best_model.coef_)\n",
		"\n",
		"# Create a DataFrame to store feature importances\n",
		"feature_importance = pd.DataFrame({'Feature': train_features_processed.columns, 'Importance': importances})\n",
		"feature_importance = feature_importance.sort_values('Importance', ascending=False).head(20)\n",
		"\n",
		"# Visualize feature importances\n",
		"plt.figure(figsize=(12, 8))\n",
		"\n",
		"sns.barplot(x='Importance', y='Feature', data=feature_importance, palette='viridis')\n",
		"plt.title(f'Top 20 Feature Importances - {best_model_name}', fontsize=14)\n",
		"plt.grid(axis='x')\n",
		"\n",
		"plt.tight_layout()\n",
		"plt.show()\n",
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.6 Prediksi pada Test Data dan Analisis Residual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Prediksi pada data training untuk memeriksa overfitting\n",
        "train_pred_log = best_model.predict(train_features_processed)\n",
        "train_pred = np.expm1(train_pred_log)\n",
        "\n",
        "# Hitung residual pada data training\n",
        "train_residuals = train_labels_clean - train_pred\n",
        "train_rmse = np.sqrt(mean_squared_error(train_labels_clean, train_pred))\n",
        "train_r2 = r2_score(train_labels_clean, train_pred)\n",
        "\n",
        "print(f\"Training RMSE: {train_rmse:.6f}\")\n",
        "print(f\"Training R²: {train_r2:.6f}\")\n",
        "\n",
        "# Visualisasi residual\n",
        "plt.figure(figsize=(16, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(train_pred, train_residuals, alpha=0.5)\n",
        "plt.axhline(y=0, color='r', linestyle='--')\n",
        "plt.xlabel('Predicted Values', fontsize=12)\n",
        "plt.ylabel('Residuals', fontsize=12)\n",
        "plt.title('Residual Plot (Training Data)', fontsize=14)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.histplot(train_residuals, kde=True, color='blue')\n",
        "plt.xlabel('Residuals', fontsize=12)\n",
        "plt.ylabel('Frequency', fontsize=12)\n",
        "plt.title('Residual Distribution', fontsize=14)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot actual vs predicted\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(train_labels_clean, train_pred, alpha=0.5)\n",
        "plt.plot([train_labels_clean.min(), train_labels_clean.max()], [train_labels_clean.min(), train_labels_clean.max()], 'r--')\n",
        "plt.xlabel('Actual Prices', fontsize=12)\n",
        "plt.ylabel('Predicted Prices', fontsize=12)\n",
        "plt.title('Actual vs Predicted (Training Data)', fontsize=14)\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.7 Prediksi pada Data Test dan Ekspor Hasil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Prediksi pada data test\n",
        "test_predictions_log = best_model.predict(test_features_processed)\n",
        "test_predictions = np.expm1(test_predictions_log)\n",
        "\n",
        "# Buat submission file\n",
        "submission = pd.DataFrame({\n",
        "    'Id': test_ID,\n",
        "    'SalePrice': test_predictions\n",
        "})\n",
        "\n",
        "submission.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Simpan hasil prediksi ke file CSV\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "print(\"Hasil prediksi telah disimpan ke 'submission.csv'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Optimasi Hyperparameter untuk Model Terbaik\n",
        "\n",
        "Setelah mengidentifikasi model terbaik, kita dapat melakukan tuning hyperparameter untuk meningkatkan performa model tersebut."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Grid Search untuk model terbaik (sesuaikan parameter grid berdasarkan model terbaik)\n",
        "param_grid = {}\n",
        "\n",
        "if best_model_name == \"Linear Regression\":\n",
        "    # Linear Regression tidak memiliki hyperparameter untuk di-tune\n",
        "    print(\"Linear Regression tidak memerlukan tuning hyperparameter.\")\n",
        "    best_tuned_model = best_model\n",
        "    \n",
        "elif best_model_name == \"Ridge Regression\":\n",
        "    param_grid = {\n",
        "        'alpha': [0.01, 0.1, 1.0, 5.0, 10.0, 20.0, 50.0, 100.0]\n",
        "    }\n",
        "    grid_search = GridSearchCV(Ridge(), param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "    grid_search.fit(train_features_processed, train_labels_log)\n",
        "    best_tuned_model = grid_search.best_estimator_\n",
        "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "    \n",
        "elif best_model_name == \"Lasso Regression\":\n",
        "    param_grid = {\n",
        "        'alpha': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0]\n",
        "    }\n",
        "    grid_search = GridSearchCV(Lasso(), param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "    grid_search.fit(train_features_processed, train_labels_log)\n",
        "    best_tuned_model = grid_search.best_estimator_\n",
        "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "    \n",
        "elif best_model_name == \"ElasticNet\":\n",
        "    param_grid = {\n",
        "        'alpha': [0.0001, 0.001, 0.01, 0.1, 1.0],\n",
        "        'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9]\n",
        "    }\n",
        "    grid_search = GridSearchCV(ElasticNet(), param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "    grid_search.fit(train_features_processed, train_labels_log)\n",
        "    best_tuned_model = grid_search.best_estimator_\n",
        "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "    \n",
        "elif best_model_name == \"Random Forest\":\n",
        "    param_grid = {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [None, 10, 20, 30],\n",
        "        'min_samples_split': [2, 5, 10],\n",
        "        'min_samples_leaf': [1, 2, 4]\n",
        "    }\n",
        "    grid_search = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "    grid_search.fit(train_features_processed, train_labels_log)\n",
        "    best_tuned_model = grid_search.best_estimator_\n",
        "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "    \n",
        "elif best_model_name == \"Gradient Boosting\":\n",
        "    param_grid = {\n",
        "        'n_estimators': [100, 200, 300],\n",
        "        'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "        'max_depth': [3, 4, 5, 6],\n",
        "        'min_samples_split': [2, 5, 10]\n",
        "    }\n",
        "    grid_search = GridSearchCV(GradientBoostingRegressor(random_state=42), param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "    grid_search.fit(train_features_processed, train_labels_log)\n",
        "    best_tuned_model = grid_search.best_estimator_\n",
        "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "    \n",
        "elif best_model_name == \"XGBoost\":\n",
        "    param_grid = {\n",
        "        'n_estimators': [100, 200, 300],\n",
        "        'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "        'max_depth': [3, 4, 5, 6],\n",
        "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
        "        'subsample': [0.6, 0.8, 1.0]\n",
        "    }\n",
        "    grid_search = GridSearchCV(xgb.XGBRegressor(random_state=42), param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "    grid_search.fit(train_features_processed, train_labels_log)\n",
        "    best_tuned_model = grid_search.best_estimator_\n",
        "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "    \n",
        "else:  # LightGBM\n",
        "    param_grid = {\n",
        "        'n_estimators': [100, 200, 300],\n",
        "        'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "        'max_depth': [3, 4, 5, 6],\n",
        "        'num_leaves': [31, 50, 80],\n",
        "        'colsample_bytree': [0.6, 0.8, 1.0]\n",
        "    }\n",
        "    grid_search = GridSearchCV(lgb.LGBMRegressor(random_state=42), param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "    grid_search.fit(train_features_processed, train_labels_log)\n",
        "    best_tuned_model = grid_search.best_estimator_\n",
        "    print(f\"Best parameters: {grid_search.best_params_}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Evaluate the tuned model on validation set\n",
        "tuned_val_pred = best_tuned_model.predict(X_val)\n",
        "tuned_metrics = evaluate_model(y_val, tuned_val_pred, \"Tuned \" + best_model_name)\n",
        "\n",
        "# Compare with original model\n",
        "if best_model_name == \"Linear Regression\":\n",
        "    original_val_pred = lr.predict(X_val)\n",
        "elif best_model_name == \"Ridge Regression\":\n",
        "    original_val_pred = ridge.predict(X_val)\n",
        "elif best_model_name == \"Lasso Regression\":\n",
        "    original_val_pred = lasso.predict(X_val)\n",
        "elif best_model_name == \"ElasticNet\":\n",
        "    original_val_pred = elastic.predict(X_val)\n",
        "elif best_model_name == \"Random Forest\":\n",
        "    original_val_pred = rf.predict(X_val)\n",
        "elif best_model_name == \"Gradient Boosting\":\n",
        "    original_val_pred = gb.predict(X_val)\n",
        "elif best_model_name == \"XGBoost\":\n",
        "    original_val_pred = xgb_reg.predict(X_val)\n",
        "else:  # LightGBM\n",
        "    original_val_pred = lgb_reg.predict(X_val)\n",
        "\n",
        "original_metrics = evaluate_model(y_val, original_val_pred, \"Original \" + best_model_name)\n",
        "\n",
        "# Compare performance\n",
        "comparison_tuned = pd.DataFrame({\n",
        "    'Model': [\"Original \" + best_model_name, \"Tuned \" + best_model_name],\n",
        "    'MSE': [original_metrics['mse'], tuned_metrics['mse']],\n",
        "    'RMSE': [original_metrics['rmse'], tuned_metrics['rmse']],\n",
        "    'R²': [original_metrics['r2'], tuned_metrics['r2']]\n",
        "})\n",
        "\n",
        "print(\"Perbandingan model original vs tuned:\")\n",
        "print(comparison_tuned)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Model Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Ensemble model with averaging\n",
        "# We'll use the top 3 models\n",
        "top_models = comparison.iloc[:3]['Model'].values\n",
        "print(f\"Top 3 models untuk ensemble: {top_models}\")\n",
        "\n",
        "# Mendapatkan prediksi dari top models\n",
        "predictions = []\n",
        "\n",
        "for model_name in top_models:\n",
        "    if model_name == \"Linear Regression\":\n",
        "        pred = lr.predict(X_val)\n",
        "    elif model_name == \"Ridge Regression\":\n",
        "        pred = ridge.predict(X_val)\n",
        "    elif model_name == \"Lasso Regression\":\n",
        "        pred = lasso.predict(X_val)\n",
        "    elif model_name == \"ElasticNet\":\n",
        "        pred = elastic.predict(X_val)\n",
        "    elif model_name == \"Random Forest\":\n",
        "        pred = rf.predict(X_val)\n",
        "    elif model_name == \"Gradient Boosting\":\n",
        "        pred = gb.predict(X_val)\n",
        "    elif model_name == \"XGBoost\":\n",
        "        pred = xgb_reg.predict(X_val)\n",
        "    else:  # LightGBM\n",
        "        pred = lgb_reg.predict(X_val)\n",
        "    predictions.append(pred)\n",
        "\n",
        "# Averaging predictions\n",
        "ensemble_pred = np.mean(predictions, axis=0)\n",
        "ensemble_metrics = evaluate_model(y_val, ensemble_pred, \"Ensemble (Top 3 Models)\")\n",
        "\n",
        "# Add ensemble to comparison\n",
        "comparison_with_ensemble = pd.concat([comparison, pd.DataFrame({\n",
        "    'Model': [\"Ensemble (Top 3 Models)\"],\n",
        "    'MSE': [ensemble_metrics['mse']],\n",
        "    'RMSE': [ensemble_metrics['rmse']],\n",
        "    'R²': [ensemble_metrics['r2']]\n",
        "})])\n",
        "\n",
        "# Sort by RMSE\n",
        "comparison_with_ensemble = comparison_with_ensemble.sort_values('RMSE')\n",
        "comparison_with_ensemble.reset_index(drop=True, inplace=True)\n",
        "print(\"\\nFinal model ranking including ensemble:\")\n",
        "print(comparison_with_ensemble)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Final Prediction dengan Model Terbaik\n",
        "\n",
        "Sekarang kita akan menggunakan model terbaik (setelah tuning dan/atau ensemble) untuk membuat prediksi final pada data test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Pilih model akhir berdasarkan perbandingan (model ensemble atau tuned model)\n",
        "best_final_model_name = comparison_with_ensemble.iloc[0]['Model']\n",
        "print(f\"Model terbaik final: {best_final_model_name}\")\n",
        "\n",
        "# Prediksi final pada data test\n",
        "if best_final_model_name == \"Ensemble (Top 3 Models)\":\n",
        "    # Gunakan ensemble untuk prediksi final\n",
        "    predictions_test = []\n",
        "    for model_name in top_models:\n",
        "        if model_name == \"Linear Regression\":\n",
        "            pred = lr.predict(test_features_processed)\n",
        "        elif model_name == \"Ridge Regression\":\n",
        "            pred = ridge.predict(test_features_processed)\n",
        "        elif model_name == \"Lasso Regression\":\n",
        "            pred = lasso.predict(test_features_processed)\n",
        "        elif model_name == \"ElasticNet\":\n",
        "            pred = elastic.predict(test_features_processed)\n",
        "        elif model_name == \"Random Forest\":\n",
        "            pred = rf.predict(test_features_processed)\n",
        "        elif model_name == \"Gradient Boosting\":\n",
        "            pred = gb.predict(test_features_processed)\n",
        "        elif model_name == \"XGBoost\":\n",
        "            pred = xgb_reg.predict(test_features_processed)\n",
        "        else:  # LightGBM\n",
        "            pred = lgb_reg.predict(test_features_processed)\n",
        "        predictions_test.append(pred)\n",
        "    \n",
        "    final_test_predictions_log = np.mean(predictions_test, axis=0)\n",
        "else:\n",
        "    # Gunakan model tunggal terbaik (setelah tuning)\n",
        "    final_test_predictions_log = best_tuned_model.predict(test_features_processed)\n",
        "\n",
        "# Transform kembali dari log ke nilai asli\n",
        "final_test_predictions = np.expm1(final_test_predictions_log)\n",
        "\n",
        "# Buat submission final\n",
        "final_submission = pd.DataFrame({\n",
        "    'Id': test_ID,\n",
        "    'SalePrice': final_test_predictions\n",
        "})\n",
        "\n",
        "# Simpan hasil akhir\n",
        "final_submission.to_csv('final_submission.csv', index=False)\n",
        "print(\"\\nHasil prediksi akhir telah disimpan ke 'final_submission.csv'\")\n",
        "final_submission.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Kesimpulan\n",
        "\n",
        "Dalam notebook ini, kita telah melakukan analisis komprehensif pada dataset Ames Housing untuk memprediksi harga rumah. Berikut rangkuman langkah-langkah yang telah dilakukan:\n",
        "\n",
        "1. **Exploratory Data Analysis (EDA)**:\n",
        "   - Analisis distribusi variabel target (SalePrice)\n",
        "   - Identifikasi dan penanganan missing values\n",
        "   - Analisis korelasi antara fitur numerik dan SalePrice\n",
        "   - Visualisasi hubungan antara fitur kategorikal dan SalePrice\n",
        "\n",
        "2. **Feature Engineering**:\n",
        "   - Penanganan missing values dengan strategi yang sesuai\n",
        "   - Transformasi distribusi fitur numerik yang skewed\n",
        "   - Encoding fitur kategorikal (Label Encoding dan One-Hot Encoding)\n",
        "   - Pembuatan fitur baru yang lebih informatif\n",
        "   - Standardisasi fitur numerik\n",
        "\n",
        "3. **Model Building dan Evaluasi**:\n",
        "   - Implementasi berbagai model regresi (Linear, Ridge, Lasso, ElasticNet, Random Forest, Gradient Boosting, XGBoost, LightGBM)\n",
        "   - Evaluasi model menggunakan MSE, RMSE, dan R²\n",
        "   - Optimasi hyperparameter untuk model terbaik\n",
        "   - Implementasi model ensemble untuk meningkatkan performa\n",
        "\n",
        "4. **Hasil dan Wawasan**:\n",
        "   - Fitur yang paling berpengaruh terhadap harga rumah\n",
        "   - Perbandingan performa berbagai model\n",
        "   - Analisis residual untuk mendeteksi potensi masalah\n",
        "\n",
        "### Metrik Evaluasi yang Digunakan:\n",
        "\n",
        "1. **Mean Squared Error (MSE)**:\n",
        "   $$\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$$\n",
        "\n",
        "2. **Root Mean Squared Error (RMSE)**:\n",
        "   $$\\text{RMSE} = \\sqrt{\\text{MSE}} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}$$\n",
        "\n",
        "3. **R-squared (R²)**:\n",
        "   $$R^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}$$\n",
        "\n",
        "### Wawasan Utama dari Analisis:\n",
        "\n",
        "1. **Faktor Penentu Harga Rumah**:\n",
        "   - Kualitas keseluruhan rumah (OverallQual) adalah prediktor terkuat untuk harga rumah\n",
        "   - Luas area hidup (GrLivArea) juga memiliki pengaruh signifikan\n",
        "   - Lokasi (Neighborhood) sangat mempengaruhi harga rumah\n",
        "   - Umur rumah dan waktu sejak renovasi terakhir mempengaruhi harga\n",
        "\n",
        "2. **Performa Model**:\n",
        "   - Model berbasis tree (Random Forest, Gradient Boosting, XGBoost, LightGBM) umumnya memberikan performa lebih baik dibandingkan model linear\n",
        "   - Ensemble model memberikan peningkatan performa tambahan\n",
        "   - Transformasi logaritmik pada target variable (SalePrice) membantu meningkatkan performa model\n",
        "\n",
        "3. **Feature Engineering**:\n",
        "   - Pembuatan fitur gabungan (seperti TotalSF, TotalBathrooms) membantu model menangkap pola yang lebih kompleks\n",
        "   - Transformasi fitur dengan skew tinggi meningkatkan normalitas dan performa model\n",
        "   - Encoding yang tepat untuk fitur kategorikal meningkatkan informasi yang dapat digunakan oleh model\n",
        "\n",
        "Model final yang telah dikembangkan dapat digunakan untuk memprediksi harga rumah dengan akurasi yang baik berdasarkan berbagai fitur properti."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Ames Housing Dataset_ EDA, Feature Engineering & Modeling.ipynb",
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}